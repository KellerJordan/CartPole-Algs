{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning\n",
    "\n",
    "Code from http://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create factory for transitions, class to remember replays of transitions\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# deep Q-network: three convolutional layers with batchnorm, two outputs (left or right)\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(448, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keller/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADWCAYAAADBwHkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3cwsEy7oZmaZ+H/wpxsOgOXRlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa25c590d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Scale(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "# This is based on the code from gym.\n",
    "screen_width = 600\n",
    "\n",
    "\n",
    "def get_cart_location():\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render(mode='rgb_array').transpose(\n",
    "        (2, 0, 1))  # transpose into torch order (CHW)\n",
    "    # Strip off the top and bottom of the screen\n",
    "    screen = screen[:, 160:320]\n",
    "    view_width = 320\n",
    "    cart_location = get_cart_location()\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescare, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).type(Tensor)\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
